{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lzVowbQRNAT2","outputId":"c4fece15-086a-458a-d8e3-dd490d6c6c75","executionInfo":{"status":"ok","timestamp":1666108134512,"user_tz":-480,"elapsed":24986,"user":{"displayName":"Shen Wuyue","userId":"04626009230572790163"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive not mounted, so nothing to flush and unmount.\n","Mounted at /content/drive\n"]}],"source":["# 读取谷歌云盘的数据请求\n","from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/content/drive', force_remount=False)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1666108141290,"user":{"displayName":"Shen Wuyue","userId":"04626009230572790163"},"user_tz":-480},"id":"MoIiS6IPROqb","outputId":"abf76ccf-981d-452f-f1b6-0aeb2bb9c141"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Colab Notebooks', 'Experiment', 'Colab-Notebooks']\n"]}],"source":["# !cd '/content/drive/MyDrive'\n","import os\n","# # os.chdir('/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis')\n","# # os.chdir('/content/drive')\n","# import torch '/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Experiment 1/GAF-MTF without DA/12k Drive End Bearing Fault Data'\n","datafiles = os.listdir('/content/drive/MyDrive/')\n","print(datafiles)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665835168252,"user":{"displayName":"Shen Wuyue","userId":"04626009230572790163"},"user_tz":-480},"id":"5gzkGn0mkzOR","outputId":"9a69aca9-cb5a-486a-d975-1aa19ba45ad4"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}],"source":["import torch\n","print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CRfQKWdBNal0"},"outputs":[],"source":["!pip install pyts --target=/content/drive/MyDrive/Colab-Notebooks/python_packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1665837541566,"user":{"displayName":"Shen Wuyue","userId":"04626009230572790163"},"user_tz":-480},"id":"e1atMyLJGbDJ","outputId":"dbb6a42e-8582-42e5-9b96-43f63066ae90"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Oct 15 12:39:01 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"id":"OmfNeW7vq9Az","outputId":"9fb7bc32-1923-44a9-87ff-696750eeb995","executionInfo":{"status":"error","timestamp":1666108365907,"user_tz":-480,"elapsed":210932,"user":{"displayName":"Shen Wuyue","userId":"04626009230572790163"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:120: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:121: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["************************* epoch 1 *************************\n"]},{"output_type":"stream","name":"stderr","text":["1889it [01:10, 26.74it/s]\n","811it [00:02, 404.33it/s]"]},{"output_type":"stream","name":"stdout","text":["Finish 1 epoch, Loss_train: 2.102782, Loss_test: 1.944243, Acc1_train: 0.460032, Acc2_train: 0.443092, Acc1_test: 0.543773, Acc2_test: 0.561036\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-17749e1ba79f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mMax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_loss1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrunning_loss2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_acc1_train\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_acc2_train\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_acc1_test\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_acc2_test\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0macclist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_acc1_test\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mrunning_acc2_test\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Models/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtesttype\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\tfinish training!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Models/Ex1_48kDE_withDA0'"]}],"source":["# 测试两个type和两个severity，GAF/MTF，CNN\n","\n","# focus on file '12k Drive End Bearing Fault Data'\n","\n","import os, sys\n","import scipy.io as io\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import pylab\n","from PIL import Image\n","from torch.autograd import Variable\n","from tqdm import tqdm\n","import logging\n","import time\n","\n","plt.rc('font',family='Times New Roman')\n","\n","# GPU\n","device='cuda:0'\n","\n","# Change the path here to test different data sources and data augmentation methods.\n","path1 = '/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Experiment 1/GAF-MTF without DA/12k Drive End Bearing Fault Data'\n","path2 = '/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Experiment 1/GAF-MTF without DA/12k Fan End Bearing Fault Data'\n","path3 = '/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Experiment 1/GAF-MTF without DA/48k Drive End Bearing Fault Data'\n","path4 = '/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Experiment 1/GAF-MTF DA/12k Drive End Bearing Fault Data'\n","path5 = '/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Experiment 1/GAF-MTF DA/12k Fan End Bearing Fault Data'\n","path6 = '/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Experiment 1/GAF-MTF DA/48k Drive End Bearing Fault Data'\n","path = path6\n","\n","# Edit the corresponding testtype.\n","testtype1 = 'Ex1_12kDE_withoutDA'\n","testtype2 = 'Ex1_12FE_withoutDA'\n","testtype3 = 'Ex1_48kDE_withoutDA'\n","testtype4 = 'Ex1_12kDE_withDA'\n","testtype5 = 'Ex1_12FE_withDA'\n","testtype6 = 'Ex1_48kDE_withDA'\n","testtype = testtype6\n","\n","\n","def gen_data():\n","    f={'Ball':0,'Inner':1,'Outer':2,'7':0,'14':1,'21':2,'28':3}\n","\n","    datafiles = os.listdir(path)\n","    lentrain = int(len(datafiles) * 0.7)\n","    lentest = len(datafiles) - lentrain\n","    X, Y1, Y2=[], [], []\n","    for file in datafiles:\n","        dataGAF = io.loadmat(os.path.join(path, file))['GAF']\n","        dataMTF = io.loadmat(os.path.join(path, file))['MTF']\n","        data = [dataGAF, dataMTF]\n","        y1, y2, _ = file.split('_')\n","        Y1.append(f[y1])\n","        Y2.append(f[y2])\n","        X.append(data)\n","\n","    X = torch.tensor(np.array(X).reshape((len(X),2, 256, 256)))\n","    Y1 = torch.tensor(np.array(Y1).reshape((len(X), 1))).to(torch.long)\n","    Y2 = torch.tensor(np.array(Y2).reshape((len(X), 1))).to(torch.long)\n","\n","    n=len(X)\n","    idx = torch.randperm(n)\n","    X_train = X[idx[:lentrain],]\n","    X_test = X[idx[lentrain:],]\n","    Y1_train = Y1[idx[:lentrain],]\n","    Y1_test = Y1[idx[lentrain:],]\n","    Y2_train = Y2[idx[:lentrain],]\n","    Y2_test = Y2[idx[lentrain:],]\n","\n","    return X_train, Y1_train, Y2_train, X_test, Y1_test, Y2_test\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","\n","        self.conv = nn.Conv2d(2, 8, kernel_size=15, padding=7) \n","        self.conv1 = nn.Conv2d(8, 16, kernel_size=5, padding=2) \n","        self.conv2 = nn.Conv2d(8, 16, kernel_size=5, padding=2) \n","        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n","        self.conv4 = nn.Conv2d(16, 32, kernel_size=3, padding=1) \n","\n","        self.mp = nn.MaxPool2d(2)\n","        self.relu = nn.ReLU()\n","        self.tanh = nn.Tanh()\n","        self.fc1 = nn.Linear(32*32*32,1000)\n","        self.fc2 = nn.Linear(32*32*32,1000)\n","        self.fc3 = nn.Linear(1000,100)\n","        self.fc4 = nn.Linear(1000,100)\n","        self.fc5 = nn.Linear(100,3)\n","        self.fc6 = nn.Linear(100,3)\n","        self.sigmod=nn.Sigmoid()\n","        self.logsoftmax = nn.LogSoftmax()\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, x):\n","        out = self.mp(self.conv(x))\n","\n","        out1 = self.mp(self.conv1(out))\n","        out1 = self.mp(self.conv3(out1))\n","        out1 = out1.view(-1)\n","        out1 = self.sigmod(self.fc1(out1))\n","        out1 = self.sigmod(self.fc3(out1))\n","        out1 = self.sigmod(self.fc5(out1))\n","\n","        out2 = self.mp(self.conv2(out))\n","        out2 = self.mp(self.conv4(out2))\n","        out2 = out2.view(-1)\n","        out2 = self.sigmod(self.fc2(out2))\n","        out2 = self.sigmod(self.fc4(out2))\n","        out2 = self.sigmod(self.fc6(out2))\n","\n","        return out1, out2\n","\n","X_train, Y1_train, Y2_train, X_test, Y1_test, Y2_test = gen_data()\n","\n","X_train=torch.tensor(X_train).to(device)\n","Y1_train=torch.tensor(Y1_train).to(device)\n","Y2_train=torch.tensor(Y2_train).to(device)\n","X_test=torch.tensor(X_test).to(device)\n","Y1_test=torch.tensor(Y1_test).to(device)\n","Y2_test=torch.tensor(Y2_test).to(device)\n","\n","\n","model = Net()\n","model=model.to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","logs = str(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime()))+'\\tstart training!'\n","\n","Max_epoch = 40\n","acclist = []\n","for epoch in range(Max_epoch):\n","    print('*' * 25, 'epoch {}'.format(epoch + 1), '*' * 25)\n","    running_loss1 = 0.0\n","    running_loss2 = 0.0\n","    running_acc1_train = 0.0\n","    running_acc2_train = 0.0\n","    n = len(X_test)\n","    if epoch==0 or running_acc1_test*running_acc2_test==0.0:\n","      w1, w2 = 0.5, 0.5\n","    else:\n","      w1, w2 = (n-running_acc1_test)/(2*n-running_acc1_test-running_acc2_test), (n-running_acc2_test)/(2*n-running_acc1_test-running_acc2_test)\n","\n","    running_acc1_test = 0.0\n","    running_acc2_test = 0.0\n","\n","    for t,x in tqdm(enumerate(X_train)):\n","        data, target1, target2 = Variable(x.reshape((1,) + x.shape)), Variable(Y1_train[t]).to(torch.long), Variable(Y2_train[t]).to(torch.long)\n","        # b_x,b_y,b_y1 = data.cuda(),target1.cuda(),target2.cuda()\n","        b_x, b_y1, b_y2 = data, target1, target2\n","        b_x = b_x.float()\n","        model.train()\n","        optimizer.zero_grad()\n","        out,out1 = model(b_x)\n","        out = out.reshape((1,len(out)))\n","        out1 = out1.reshape((1, len(out1)))\n","        loss1 = loss_fn(out, b_y1)\n","        loss2 = loss_fn(out1,b_y2)\n","        loss = w1*loss1 + w2*loss2\n","        running_loss1 += loss1.item() * b_y1.size(0)+loss2.item() * b_y2.size(0)\n","        _, pred1 = torch.max(out, 1)\n","        _, pred2 = torch.max(out1, 1)\n","        num_correct1_train = (pred1 == b_y1).sum()\n","        num_correct2_train = (pred2 == b_y2).sum()\n","        # print(num_correct1, num_correct2)\n","        accuracy = (pred2 == b_y2).float().mean()\n","        running_acc1_train += num_correct1_train.item()\n","        running_acc2_train += num_correct2_train.item()\n","        # print(running_acc1, running_acc2)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    for t,x in tqdm(enumerate(X_test)):\n","        data, target1, target2 = Variable(x.reshape((1,) + x.shape)), Variable(Y1_test[t]).to(torch.long), Variable(Y2_test[t]).to(torch.long)\n","        # b_x,b_y,b_y1 = data.cuda(),target1.cuda(),target2.cuda()\n","        b_x, b_y1, b_y2 = data, target1, target2\n","        b_x = b_x.float()\n","        out,out1 = model(b_x)\n","        out = out.reshape((1,len(out)))\n","        out1 = out1.reshape((1, len(out1)))\n","        loss1 = loss_fn(out, b_y1)\n","        loss2 = loss_fn(out1,b_y2)\n","        running_loss2 += loss1.item() * b_y1.size(0)+loss2.item() * b_y2.size(0)\n","        _, pred1 = torch.max(out, 1)\n","        _, pred2 = torch.max(out1, 1)\n","        num_correct1_test = (pred1 == b_y1).sum()\n","        num_correct2_test = (pred2 == b_y2).sum()\n","        # print(num_correct1, num_correct2)\n","        accuracy = (pred2 == b_y2).float().mean()\n","        running_acc1_test += num_correct1_test.item()\n","        running_acc2_test += num_correct2_test.item()\n","        # print(running_acc1, running_acc2)\n","\n","    print('Finish {} epoch, Loss_train: {:.6f}, Loss_test: {:.6f}, Acc1_train: {:.6f}, Acc2_train: {:.6f}, Acc1_test: {:.6f}, Acc2_test: {:.6f}'.format(\n","        epoch + 1, running_loss1 / len(X_train), running_loss2 / len(X_test), running_acc1_train / len(X_train), running_acc2_train / len(X_train), running_acc1_test / len(X_test), running_acc2_test / len(X_test)))\n","    logs += '\\n'+str(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime()))+'\\tEpoch:[{}/{}]\\t loss_train={:.5f}\\t loss_test={:.5f}\\t Acc1_train={:.5f}\\t Acc2_train={:.5f}\\t Acc1_test={:.5f}\\t Acc2_test={:.5f}'.\\\n","                format(epoch+1 , Max_epoch, running_loss1 / len(X_train),running_loss2 / len(X_test), running_acc1_train / len(X_train), running_acc2_train / len(X_train), running_acc1_test / len(X_test), running_acc2_test / len(X_test)  )\n","    acclist.append([(running_acc1_test / len(X_test)+ running_acc2_test / len(X_test))/2,epoch])\n","    torch.save(model,'/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Models/'+testtype+str(epoch))\n","\n","logs += '\\n' + str(time.strftime(\"%Y-%m-%d %H:%M:%S\",time.localtime())) + '\\tfinish training!'\n","acclist.sort(reverse=True)\n","best_epoch=acclist[0][1]\n","for epoch in range(Max_epoch):\n","  if epoch==best_epoch:\n","    model = torch.load('/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Models/'+testtype+str(epoch))\n","    torch.save(model,'/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Models/'+testtype)\n","  os.remove('/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Models/'+testtype+str(epoch))\n","# testtype = 'Ex1_12kDE_withoutDA'\n","\n","logs += '\\nBest epoch:'+str(best_epoch+1)\n","with open('/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Logs/'+testtype+'.log','w+') as f:\n","    f.write(logs)\n","torch.save(model, '/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis/Models/'+testtype)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":3465,"status":"error","timestamp":1665835371437,"user":{"displayName":"Shen Wuyue","userId":"04626009230572790163"},"user_tz":-480},"id":"mhaEO2Nosm1e","outputId":"37bbcc33-5611-45b6-ddd4-efd9dcf5f75d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive not mounted, so nothing to flush and unmount.\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-9e0f2afe0e34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_and_unmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mephemeral\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       readonly=readonly)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"]}],"source":["# 读取谷歌云盘的数据请求\n","from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/content/drive', force_remount=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665402846812,"user":{"displayName":"Zhang Jierui","userId":"04626009230572790163"},"user_tz":-480},"id":"tPnw5-lqs6Y9","outputId":"02d38391-9b29-4b86-9922-6cb30615ef97"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["import os, sys\n","path = os.getcwd()\n","datafiles = os.listdir('/content/drive/MyDrive/Colab Notebooks/Bearing Fault Diagnosis')\n","print(path)\n"]},{"cell_type":"markdown","metadata":{"id":"EWQ8t8HWrSWb"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPAvvZQgq07sQrGy2xBHSk5"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}